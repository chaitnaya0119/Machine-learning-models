{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"F:\\Machine Learning\\logistic regression\\data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Survived',axis=1)\n",
    "y=data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.152164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.346569</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.308872</td>\n",
       "      <td>0.177775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.195778</td>\n",
       "      <td>0.076904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0    0.371701  0.024350       0.0       0.0       1.0         1.0       0.0   \n",
       "1    0.334004  0.016908       0.0       0.0       1.0         0.0       1.0   \n",
       "2    0.396833  0.015127       0.0       0.0       1.0         0.0       1.0   \n",
       "3    0.786378  0.152164       1.0       0.0       0.0         1.0       0.0   \n",
       "4    0.334004  0.412821       1.0       0.0       0.0         0.0       1.0   \n",
       "..        ...       ...       ...       ...       ...         ...       ...   \n",
       "663  0.371701  0.025374       0.0       1.0       0.0         0.0       1.0   \n",
       "664  0.233476  0.015330       0.0       0.0       1.0         1.0       0.0   \n",
       "665  0.346569  0.024691       0.0       1.0       0.0         1.0       0.0   \n",
       "666  0.308872  0.177775       1.0       0.0       0.0         0.0       1.0   \n",
       "667  0.195778  0.076904       1.0       0.0       0.0         1.0       0.0   \n",
       "\n",
       "     SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0        1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "1        1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2        1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3        0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4        1.0      0.0      0.0  ...      0.0      0.0      1.0      0.0   \n",
       "..       ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "663      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "664      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "665      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "666      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "667      1.0      0.0      0.0  ...      0.0      1.0      0.0      0.0   \n",
       "\n",
       "     Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1        0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2        0.0      0.0      0.0         0.0         1.0         0.0  \n",
       "3        0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4        0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "..       ...      ...      ...         ...         ...         ...  \n",
       "663      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "664      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "665      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "666      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "667      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "\n",
       "[668 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train = scaler.fit_transform(x_train)\n",
    "train_x_scaled = pd.DataFrame(scaled_train,columns=x_train.columns)\n",
    "train_x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448029</td>\n",
       "      <td>0.143462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405018</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.415041</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390681</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.054164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.204301</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.390681</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.347670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.620072</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.415041</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0    0.448029  0.143462       0.0       1.0       0.0         0.0       1.0   \n",
       "1    0.405018  0.129995       1.0       0.0       0.0         0.0       1.0   \n",
       "2    0.415041  0.014110       0.0       0.0       1.0         0.0       1.0   \n",
       "3    0.390681  0.025374       0.0       1.0       0.0         1.0       0.0   \n",
       "4    0.419355  0.054164       1.0       0.0       0.0         0.0       1.0   \n",
       "..        ...       ...       ...       ...       ...         ...       ...   \n",
       "218  0.204301  0.028213       0.0       0.0       1.0         1.0       0.0   \n",
       "219  0.390681  0.046845       0.0       1.0       0.0         1.0       0.0   \n",
       "220  0.347670  0.000000       0.0       0.0       1.0         0.0       1.0   \n",
       "221  0.620072  0.050749       0.0       1.0       0.0         0.0       1.0   \n",
       "222  0.415041  0.031425       0.0       0.0       1.0         0.0       1.0   \n",
       "\n",
       "     SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0        0.0      0.0      1.0  ...      1.0      0.0      0.0      0.0   \n",
       "1        0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2        1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3        1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4        1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "..       ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "218      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "219      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "220      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "221      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "222      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "\n",
       "     Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1        0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2        0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "3        0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4        0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "..       ...      ...      ...         ...         ...         ...  \n",
       "218      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "219      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "220      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "221      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "222      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "\n",
       "[223 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test = scaler.fit_transform(x_test)\n",
    "test_x_scaled = pd.DataFrame(scaled_test,columns=x_test.columns)\n",
    "test_x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chaitanya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = lg.predict(x_train)\n",
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = lg.predict(x_test)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7514910536779325"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k= f1_score(train_pred,y_train)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.736842105263158"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = f1_score(test_pred,y_test)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions Using Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51806512, 0.48193488],\n",
       "       [0.90673487, 0.09326513],\n",
       "       [0.87357922, 0.12642078],\n",
       "       ...,\n",
       "       [0.22486599, 0.77513401],\n",
       "       [0.31155009, 0.68844991],\n",
       "       [0.0438472 , 0.9561528 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict = lg.predict_proba(x_train)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82160481, 0.17839519],\n",
       "       [0.46500129, 0.53499871],\n",
       "       [0.87390636, 0.12609364],\n",
       "       [0.22469105, 0.77530895],\n",
       "       [0.44613606, 0.55386394],\n",
       "       [0.15296393, 0.84703607],\n",
       "       [0.91473019, 0.08526981],\n",
       "       [0.88348647, 0.11651353],\n",
       "       [0.96425734, 0.03574266],\n",
       "       [0.90069659, 0.09930341],\n",
       "       [0.05286066, 0.94713934],\n",
       "       [0.67651428, 0.32348572],\n",
       "       [0.09475846, 0.90524154],\n",
       "       [0.54101895, 0.45898105],\n",
       "       [0.96482333, 0.03517667],\n",
       "       [0.88697601, 0.11302399],\n",
       "       [0.05226907, 0.94773093],\n",
       "       [0.38974744, 0.61025256],\n",
       "       [0.94550787, 0.05449213],\n",
       "       [0.07296859, 0.92703141],\n",
       "       [0.51854414, 0.48145586],\n",
       "       [0.80928724, 0.19071276],\n",
       "       [0.84735116, 0.15264884],\n",
       "       [0.04233861, 0.95766139],\n",
       "       [0.71320874, 0.28679126],\n",
       "       [0.90091337, 0.09908663],\n",
       "       [0.38974744, 0.61025256],\n",
       "       [0.18046644, 0.81953356],\n",
       "       [0.06062201, 0.93937799],\n",
       "       [0.02725956, 0.97274044],\n",
       "       [0.45889774, 0.54110226],\n",
       "       [0.86796333, 0.13203667],\n",
       "       [0.89103863, 0.10896137],\n",
       "       [0.31000586, 0.68999414],\n",
       "       [0.32888179, 0.67111821],\n",
       "       [0.88617295, 0.11382705],\n",
       "       [0.3051507 , 0.6948493 ],\n",
       "       [0.77404554, 0.22595446],\n",
       "       [0.10300944, 0.89699056],\n",
       "       [0.87968321, 0.12031679],\n",
       "       [0.20072581, 0.79927419],\n",
       "       [0.87774015, 0.12225985],\n",
       "       [0.51881346, 0.48118654],\n",
       "       [0.49448051, 0.50551949],\n",
       "       [0.91279719, 0.08720281],\n",
       "       [0.75567985, 0.24432015],\n",
       "       [0.91473019, 0.08526981],\n",
       "       [0.52970874, 0.47029126],\n",
       "       [0.87390769, 0.12609231],\n",
       "       [0.92354001, 0.07645999],\n",
       "       [0.75614832, 0.24385168],\n",
       "       [0.91217156, 0.08782844],\n",
       "       [0.76100404, 0.23899596],\n",
       "       [0.25074379, 0.74925621],\n",
       "       [0.91473019, 0.08526981],\n",
       "       [0.89069439, 0.10930561],\n",
       "       [0.88715798, 0.11284202],\n",
       "       [0.92338626, 0.07661374],\n",
       "       [0.89904358, 0.10095642],\n",
       "       [0.89062338, 0.10937662],\n",
       "       [0.84027347, 0.15972653],\n",
       "       [0.80901242, 0.19098758],\n",
       "       [0.85417116, 0.14582884],\n",
       "       [0.45191056, 0.54808944],\n",
       "       [0.93946548, 0.06053452],\n",
       "       [0.6858341 , 0.3141659 ],\n",
       "       [0.87369551, 0.12630449],\n",
       "       [0.38981   , 0.61019   ],\n",
       "       [0.87955077, 0.12044923],\n",
       "       [0.25557144, 0.74442856],\n",
       "       [0.91473019, 0.08526981],\n",
       "       [0.16448292, 0.83551708],\n",
       "       [0.96908185, 0.03091815],\n",
       "       [0.08112127, 0.91887873],\n",
       "       [0.21760881, 0.78239119],\n",
       "       [0.19841494, 0.80158506],\n",
       "       [0.89702337, 0.10297663],\n",
       "       [0.87971168, 0.12028832],\n",
       "       [0.82654904, 0.17345096],\n",
       "       [0.18366296, 0.81633704],\n",
       "       [0.26430892, 0.73569108],\n",
       "       [0.38983559, 0.61016441],\n",
       "       [0.87390769, 0.12609231],\n",
       "       [0.39088232, 0.60911768],\n",
       "       [0.59722965, 0.40277035],\n",
       "       [0.58861392, 0.41138608],\n",
       "       [0.03139967, 0.96860033],\n",
       "       [0.96548189, 0.03451811],\n",
       "       [0.06548361, 0.93451639],\n",
       "       [0.30742204, 0.69257796],\n",
       "       [0.66280265, 0.33719735],\n",
       "       [0.7020381 , 0.2979619 ],\n",
       "       [0.91476468, 0.08523532],\n",
       "       [0.91476468, 0.08523532],\n",
       "       [0.4777414 , 0.5222586 ],\n",
       "       [0.90992316, 0.09007684],\n",
       "       [0.89755319, 0.10244681],\n",
       "       [0.89747403, 0.10252597],\n",
       "       [0.71585739, 0.28414261],\n",
       "       [0.91476468, 0.08523532],\n",
       "       [0.90692068, 0.09307932],\n",
       "       [0.52687653, 0.47312347],\n",
       "       [0.92097286, 0.07902714],\n",
       "       [0.09396983, 0.90603017],\n",
       "       [0.55053279, 0.44946721],\n",
       "       [0.45889774, 0.54110226],\n",
       "       [0.65530014, 0.34469986],\n",
       "       [0.91459306, 0.08540694],\n",
       "       [0.19654164, 0.80345836],\n",
       "       [0.54504218, 0.45495782],\n",
       "       [0.88326853, 0.11673147],\n",
       "       [0.16315285, 0.83684715],\n",
       "       [0.04568299, 0.95431701],\n",
       "       [0.57242261, 0.42757739],\n",
       "       [0.8942355 , 0.1057645 ],\n",
       "       [0.92860708, 0.07139292],\n",
       "       [0.93512899, 0.06487101],\n",
       "       [0.02352706, 0.97647294],\n",
       "       [0.65130518, 0.34869482],\n",
       "       [0.95232959, 0.04767041],\n",
       "       [0.9032483 , 0.0967517 ],\n",
       "       [0.77576911, 0.22423089],\n",
       "       [0.11081622, 0.88918378],\n",
       "       [0.66651476, 0.33348524],\n",
       "       [0.30333224, 0.69666776],\n",
       "       [0.94900927, 0.05099073],\n",
       "       [0.14009099, 0.85990901],\n",
       "       [0.49549074, 0.50450926],\n",
       "       [0.49076422, 0.50923578],\n",
       "       [0.9189309 , 0.0810691 ],\n",
       "       [0.81311166, 0.18688834],\n",
       "       [0.10714378, 0.89285622],\n",
       "       [0.66806612, 0.33193388],\n",
       "       [0.11404647, 0.88595353],\n",
       "       [0.75224103, 0.24775897],\n",
       "       [0.51854414, 0.48145586],\n",
       "       [0.73664719, 0.26335281],\n",
       "       [0.20496782, 0.79503218],\n",
       "       [0.3552763 , 0.6447237 ],\n",
       "       [0.81060446, 0.18939554],\n",
       "       [0.82733668, 0.17266332],\n",
       "       [0.4499965 , 0.5500035 ],\n",
       "       [0.9095217 , 0.0904783 ],\n",
       "       [0.78672666, 0.21327334],\n",
       "       [0.87975848, 0.12024152],\n",
       "       [0.08533986, 0.91466014],\n",
       "       [0.89319941, 0.10680059],\n",
       "       [0.23746974, 0.76253026],\n",
       "       [0.86419692, 0.13580308],\n",
       "       [0.89764654, 0.10235346],\n",
       "       [0.54048159, 0.45951841],\n",
       "       [0.514273  , 0.485727  ],\n",
       "       [0.88551325, 0.11448675],\n",
       "       [0.9038557 , 0.0961443 ],\n",
       "       [0.89744764, 0.10255236],\n",
       "       [0.83375317, 0.16624683],\n",
       "       [0.75746811, 0.24253189],\n",
       "       [0.38708689, 0.61291311],\n",
       "       [0.89374337, 0.10625663],\n",
       "       [0.78859067, 0.21140933],\n",
       "       [0.9095217 , 0.0904783 ],\n",
       "       [0.89084671, 0.10915329],\n",
       "       [0.53306549, 0.46693451],\n",
       "       [0.76085085, 0.23914915],\n",
       "       [0.91242546, 0.08757454],\n",
       "       [0.88714242, 0.11285758],\n",
       "       [0.88712208, 0.11287792],\n",
       "       [0.25399786, 0.74600214],\n",
       "       [0.92356447, 0.07643553],\n",
       "       [0.49331743, 0.50668257],\n",
       "       [0.86419692, 0.13580308],\n",
       "       [0.7301964 , 0.2698036 ],\n",
       "       [0.86449681, 0.13550319],\n",
       "       [0.73363235, 0.26636765],\n",
       "       [0.59038526, 0.40961474],\n",
       "       [0.35450964, 0.64549036],\n",
       "       [0.72884434, 0.27115566],\n",
       "       [0.94666352, 0.05333648],\n",
       "       [0.12322877, 0.87677123],\n",
       "       [0.67808137, 0.32191863],\n",
       "       [0.89405952, 0.10594048],\n",
       "       [0.04384566, 0.95615434],\n",
       "       [0.73160697, 0.26839303],\n",
       "       [0.46193168, 0.53806832],\n",
       "       [0.82707182, 0.17292818],\n",
       "       [0.96845501, 0.03154499],\n",
       "       [0.83375317, 0.16624683],\n",
       "       [0.59136003, 0.40863997],\n",
       "       [0.54769213, 0.45230787],\n",
       "       [0.91556679, 0.08443321],\n",
       "       [0.87191553, 0.12808447],\n",
       "       [0.5012596 , 0.4987404 ],\n",
       "       [0.90932971, 0.09067029],\n",
       "       [0.07205972, 0.92794028],\n",
       "       [0.92600016, 0.07399984],\n",
       "       [0.49184731, 0.50815269],\n",
       "       [0.23226652, 0.76773348],\n",
       "       [0.84121616, 0.15878384],\n",
       "       [0.8930925 , 0.1069075 ],\n",
       "       [0.64515587, 0.35484413],\n",
       "       [0.16111141, 0.83888859],\n",
       "       [0.62968957, 0.37031043],\n",
       "       [0.91473019, 0.08526981],\n",
       "       [0.11123453, 0.88876547],\n",
       "       [0.89062338, 0.10937662],\n",
       "       [0.93739187, 0.06260813],\n",
       "       [0.87975848, 0.12024152],\n",
       "       [0.90086215, 0.09913785],\n",
       "       [0.8380904 , 0.1619096 ],\n",
       "       [0.11556149, 0.88443851],\n",
       "       [0.81451445, 0.18548555],\n",
       "       [0.91556679, 0.08443321],\n",
       "       [0.86446599, 0.13553401],\n",
       "       [0.91495365, 0.08504635],\n",
       "       [0.40951327, 0.59048673],\n",
       "       [0.38648203, 0.61351797],\n",
       "       [0.90927435, 0.09072565],\n",
       "       [0.05655606, 0.94344394],\n",
       "       [0.24497223, 0.75502777],\n",
       "       [0.1272825 , 0.8727175 ],\n",
       "       [0.90270396, 0.09729604],\n",
       "       [0.79895712, 0.20104288],\n",
       "       [0.89414685, 0.10585315]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = lg.predict_proba(x_test)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48193488, 0.09326513, 0.12642078, 0.7779838 , 0.63037429,\n",
       "       0.11649263, 0.84539161, 0.77530895, 0.53271607, 0.08398753,\n",
       "       0.10589511, 0.08523532, 0.12404348, 0.09614637, 0.60898515,\n",
       "       0.084256  , 0.30711199, 0.12016696, 0.07140718, 0.28747793,\n",
       "       0.10220063, 0.21867149, 0.07101918, 0.58913461, 0.09010035,\n",
       "       0.51446748, 0.085091  , 0.55860894, 0.60332195, 0.12827122,\n",
       "       0.82115405, 0.08526981, 0.58525806, 0.13579608, 0.0222337 ,\n",
       "       0.5762265 , 0.21841852, 0.12609364, 0.05840821, 0.28560345,\n",
       "       0.84130085, 0.39127453, 0.2022657 , 0.7086781 , 0.48204649,\n",
       "       0.94332879, 0.37087714, 0.2205931 , 0.16827864, 0.89246943,\n",
       "       0.13251131, 0.64077162, 0.23899596, 0.61025256, 0.34060743,\n",
       "       0.64640915, 0.78025819, 0.29296508, 0.10911843, 0.29776893,\n",
       "       0.58514092, 0.29296508, 0.12491121, 0.45757115, 0.10260096,\n",
       "       0.97664939, 0.11689792, 0.08523532, 0.86492715, 0.66435812,\n",
       "       0.93147023, 0.74983847, 0.89907458, 0.44911235, 0.8423388 ,\n",
       "       0.24584371, 0.86686478, 0.5412331 , 0.55650388, 0.12827122,\n",
       "       0.52329888, 0.12777891, 0.13198533, 0.01870853, 0.68564468,\n",
       "       0.94757508, 0.67639066, 0.07573583, 0.27835398, 0.9321111 ,\n",
       "       0.29389925, 0.13580308, 0.09082223, 0.13580308, 0.2022657 ,\n",
       "       0.9119179 , 0.34145849, 0.12404997, 0.55790456, 0.56828195,\n",
       "       0.13580308, 0.12412922, 0.09924037, 0.12839634, 0.12630449,\n",
       "       0.05288792, 0.30402951, 0.04166505, 0.7493796 , 0.30198874,\n",
       "       0.23899596, 0.4318741 , 0.12609231, 0.1360417 , 0.54096601,\n",
       "       0.33643652, 0.12414364, 0.92582206, 0.11291382, 0.13612879,\n",
       "       0.49654701, 0.46897529, 0.22561637, 0.39983547, 0.9354292 ,\n",
       "       0.33137108, 0.39132   , 0.61016441, 0.13579467, 0.67341853,\n",
       "       0.08978705, 0.09618481, 0.39134285, 0.90656375, 0.12609231,\n",
       "       0.02903307, 0.48201377, 0.06539566, 0.37971824, 0.90813709,\n",
       "       0.92904492, 0.13042846, 0.64549306, 0.10483776, 0.23336563,\n",
       "       0.2575716 , 0.10933354, 0.92972762, 0.86447492, 0.90587453,\n",
       "       0.51441675, 0.46969887, 0.6592398 , 0.07158331, 0.45389225,\n",
       "       0.08528379, 0.44631085, 0.27669189, 0.09239972, 0.80160391,\n",
       "       0.29506874, 0.27835398, 0.31522998, 0.66611415, 0.04614714,\n",
       "       0.25540388, 0.12020487, 0.82794566, 0.34617904, 0.93803615,\n",
       "       0.05114015, 0.76258797, 0.61401146, 0.28467236, 0.33041849,\n",
       "       0.47606765, 0.5084534 , 0.38129392, 0.08235065, 0.09009057,\n",
       "       0.08164687, 0.25592951, 0.04487293, 0.11524739, 0.924754  ,\n",
       "       0.3699335 , 0.93125385, 0.28515461, 0.26419929, 0.16971442,\n",
       "       0.14550005, 0.05679542, 0.57376672, 0.31819367, 0.12403569,\n",
       "       0.17118346, 0.29296508, 0.90079493, 0.63856409, 0.27151153,\n",
       "       0.44792832, 0.40509297, 0.61016441, 0.11287792, 0.21084599,\n",
       "       0.89062117, 0.62106728, 0.08305945, 0.7747032 , 0.13580308,\n",
       "       0.61270223, 0.61016441, 0.12609364, 0.15678374, 0.94526264,\n",
       "       0.08523532, 0.07399984, 0.90414852, 0.63165499, 0.1341755 ,\n",
       "       0.12028832, 0.3098527 , 0.08526981, 0.88972491, 0.2170067 ,\n",
       "       0.16318843, 0.08523532, 0.72153274, 0.46459407, 0.1387679 ,\n",
       "       0.72309677, 0.46441316, 0.08672397, 0.25540388, 0.16957396,\n",
       "       0.73902234, 0.37283042, 0.87050969, 0.11268418, 0.03804631,\n",
       "       0.24917054, 0.08619445, 0.21841852, 0.13212709, 0.64627447,\n",
       "       0.09614637, 0.66510644, 0.23899596, 0.53299045, 0.11708187,\n",
       "       0.92244297, 0.0964467 , 0.67061005, 0.80688067, 0.95893741,\n",
       "       0.15380774, 0.37714995, 0.13260474, 0.08523532, 0.44875755,\n",
       "       0.0431185 , 0.64806939, 0.08757071, 0.12490989, 0.92735728,\n",
       "       0.33035978, 0.56489653, 0.07905934, 0.08526981, 0.0852083 ,\n",
       "       0.72756627, 0.13582975, 0.84397818, 0.66653531, 0.47920513,\n",
       "       0.27322651, 0.33042936, 0.07968488, 0.29734986, 0.34134166,\n",
       "       0.064591  , 0.11649263, 0.61015302, 0.08724277, 0.0982411 ,\n",
       "       0.44586788, 0.04789881, 0.85984344, 0.09305511, 0.82614192,\n",
       "       0.90155699, 0.55194909, 0.94224934, 0.0928566 , 0.02934622,\n",
       "       0.94980314, 0.05653477, 0.31789332, 0.63887705, 0.11283484,\n",
       "       0.5308731 , 0.42906413, 0.24385168, 0.1069075 , 0.1242072 ,\n",
       "       0.04155115, 0.06785851, 0.31141423, 0.09010035, 0.80345836,\n",
       "       0.61016441, 0.45177933, 0.09908663, 0.23899596, 0.08686037,\n",
       "       0.12609231, 0.11284081, 0.18939554, 0.11655045, 0.54998575,\n",
       "       0.35592676, 0.13181653, 0.81487676, 0.94728334, 0.44446307,\n",
       "       0.31789332, 0.58967878, 0.08515801, 0.1309015 , 0.25449489,\n",
       "       0.12024152, 0.13580308, 0.0222337 , 0.26191126, 0.08523532,\n",
       "       0.16760803, 0.0967517 , 0.23601452, 0.80646432, 0.05290588,\n",
       "       0.29148194, 0.93965843, 0.07678555, 0.06913742, 0.3733086 ,\n",
       "       0.41794259, 0.64303703, 0.0418027 , 0.19518665, 0.49434172,\n",
       "       0.34911001, 0.12909291, 0.80243511, 0.29495184, 0.46777589,\n",
       "       0.80061111, 0.06341539, 0.14958476, 0.12866667, 0.24896131,\n",
       "       0.89863062, 0.64954164, 0.12827122, 0.27886429, 0.46727469,\n",
       "       0.81090751, 0.18466384, 0.08526981, 0.86566964, 0.96182898,\n",
       "       0.74908855, 0.93077072, 0.20526748, 0.66510644, 0.26469317,\n",
       "       0.42418737, 0.38533442, 0.04571235, 0.74565223, 0.85727308,\n",
       "       0.12031679, 0.73429436, 0.46139026, 0.13580308, 0.13932766,\n",
       "       0.9364026 , 0.23899596, 0.31950707, 0.30081045, 0.58006   ,\n",
       "       0.41179478, 0.35687031, 0.86518699, 0.08510496, 0.08526981,\n",
       "       0.81090751, 0.65043963, 0.06750434, 0.11291382, 0.5587606 ,\n",
       "       0.7583241 , 0.76946043, 0.90254382, 0.5070731 , 0.12656322,\n",
       "       0.11660155, 0.39270786, 0.10259646, 0.88333409, 0.38715061,\n",
       "       0.11168008, 0.55650388, 0.25729744, 0.11625543, 0.05655008,\n",
       "       0.46298655, 0.96552148, 0.9278321 , 0.57678632, 0.85412612,\n",
       "       0.46839948, 0.60911768, 0.69354309, 0.24783123, 0.80626566,\n",
       "       0.17345096, 0.94275457, 0.10588381, 0.08475529, 0.06921129,\n",
       "       0.63328096, 0.85833253, 0.09056288, 0.06260813, 0.48890665,\n",
       "       0.61016441, 0.22583184, 0.19698223, 0.59100789, 0.22961919,\n",
       "       0.18101301, 0.07903324, 0.65332459, 0.32348593, 0.62408899,\n",
       "       0.70691811, 0.92011551, 0.83175111, 0.93021472, 0.77831438,\n",
       "       0.54317124, 0.12792438, 0.08523532, 0.08672397, 0.15609357,\n",
       "       0.54963076, 0.13579746, 0.09360014, 0.21981495, 0.47678447,\n",
       "       0.07158331, 0.07369494, 0.88220805, 0.91415681, 0.96464513,\n",
       "       0.21117048, 0.14585231, 0.5696307 , 0.26191126, 0.71479938,\n",
       "       0.74644053, 0.69428774, 0.91462935, 0.93316938, 0.08526981,\n",
       "       0.45658462, 0.79927419, 0.23730995, 0.18466384, 0.61042876,\n",
       "       0.5849465 , 0.61260452, 0.08978705, 0.24353814, 0.89536896,\n",
       "       0.141419  , 0.42757739, 0.39842304, 0.65598548, 0.0869671 ,\n",
       "       0.10922884, 0.15972492, 0.72324174, 0.73120729, 0.40923038,\n",
       "       0.89891767, 0.57084235, 0.22429672, 0.07903324, 0.07903324,\n",
       "       0.07901845, 0.44631085, 0.11655424, 0.8742523 , 0.08167914,\n",
       "       0.06473773, 0.86471966, 0.26120684, 0.04163071, 0.12032119,\n",
       "       0.63648003, 0.13580308, 0.92885317, 0.32697441, 0.25540388,\n",
       "       0.13212709, 0.10915329, 0.08378462, 0.11786628, 0.27835398,\n",
       "       0.41880388, 0.75991296, 0.0222337 , 0.52444246, 0.94870736,\n",
       "       0.34580131, 0.12339363, 0.89442618, 0.48196871, 0.22701527,\n",
       "       0.4023709 , 0.73318279, 0.12093352, 0.03705525, 0.0222337 ,\n",
       "       0.08523532, 0.52341428, 0.08393974, 0.08717998, 0.04250812,\n",
       "       0.93141217, 0.06776645, 0.60154751, 0.88249993, 0.35847451,\n",
       "       0.47130111, 0.75598553, 0.55146726, 0.09611626, 0.085091  ,\n",
       "       0.0852083 , 0.08523532, 0.20643975, 0.61015588, 0.12609364,\n",
       "       0.58968169, 0.12677853, 0.0967517 , 0.10974039, 0.7450541 ,\n",
       "       0.93327235, 0.45266317, 0.32191863, 0.18466384, 0.88782965,\n",
       "       0.24364325, 0.51026695, 0.69806609, 0.8994335 , 0.72917157,\n",
       "       0.04984323, 0.61021845, 0.06413241, 0.61016441, 0.18104004,\n",
       "       0.38499685, 0.08559477, 0.1766587 , 0.11848788, 0.69480372,\n",
       "       0.07912462, 0.11308992, 0.94070595, 0.23874448, 0.21841852,\n",
       "       0.05670522, 0.88114935, 0.04124845, 0.39054791, 0.4016656 ,\n",
       "       0.71880284, 0.84338623, 0.085091  , 0.44592103, 0.82249259,\n",
       "       0.89551912, 0.12413322, 0.0356857 , 0.04364626, 0.03329153,\n",
       "       0.61016441, 0.12609364, 0.72153274, 0.05290588, 0.85475872,\n",
       "       0.65676434, 0.10232929, 0.04983407, 0.11404907, 0.2140676 ,\n",
       "       0.41149097, 0.10811655, 0.61948667, 0.14900173, 0.97369118,\n",
       "       0.78144334, 0.04894   , 0.14477203, 0.13843315, 0.66510644,\n",
       "       0.08439903, 0.61008199, 0.22942136, 0.13580308, 0.48543369,\n",
       "       0.87346181, 0.19618724, 0.94485019, 0.77962733, 0.22701527,\n",
       "       0.14999199, 0.06087662, 0.12609364, 0.10259308, 0.05472907,\n",
       "       0.08093677, 0.26419929, 0.68124404, 0.58657922, 0.71879316,\n",
       "       0.10933354, 0.13579888, 0.08523532, 0.93677186, 0.33041849,\n",
       "       0.10964235, 0.74452724, 0.94789273, 0.31844445, 0.65277198,\n",
       "       0.5171663 , 0.14064209, 0.94526264, 0.94284376, 0.69186402,\n",
       "       0.11697938, 0.94844182, 0.72614265, 0.08526981, 0.25577795,\n",
       "       0.70350575, 0.37352717, 0.48109782, 0.24385168, 0.62813753,\n",
       "       0.77513401, 0.68844991, 0.9561528 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict = train_predict[:,1]\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train_predict)):\n",
    "    if(train_predict[i]>0.55):\n",
    "        train_predict[i]=1\n",
    "    else:\n",
    "        train_predict[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7366255144032922"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = f1_score(train_predict,y_train)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  17],\n",
       "       [ 23,  56]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test,test_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       144\n",
      "           1       0.77      0.71      0.74        79\n",
      "\n",
      "    accuracy                           0.82       223\n",
      "   macro avg       0.81      0.80      0.80       223\n",
      "weighted avg       0.82      0.82      0.82       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03580725,  0.00286834,  1.02061368,  0.15416388, -1.08354292,\n",
       "         1.19491637, -1.10368173,  0.84553446,  1.06143577,  0.34803337,\n",
       "        -0.67201851, -0.7826802 , -0.28430066, -0.42476958,  0.12826575,\n",
       "         0.60007647, -0.18868608,  0.20981937, -0.3506616 , -0.14093837,\n",
       "        -0.16664089,  0.14886312,  0.23272299, -0.29035147]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Coefficient plot')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.Figure(figsize=(10,8),dpi=120,facecolor='w',edgecolor='r')\n",
    "x = range(len(x_train.columns))\n",
    "y = lg.coef_.reshape(-1)\n",
    "plt.bar(x,y)\n",
    "plt.xlabel( \"Variables\")\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Coefficient plot')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
